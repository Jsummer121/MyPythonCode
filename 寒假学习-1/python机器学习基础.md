## 机器学习基础

### 定义

- 机器学习是一门综合性非常强的多领域交叉学科，设计线性代数，概率论，统计学，算法复杂度理论等多门学科

- 机器学习根据已知数据来不断学习和基类经验，然后总结出规律并尝试预测未知数据的属性。机器学习可利用数据或经验等不断改善自身的性能

- 机器学习是目前弱人工智能的核心，其应用十分广泛，如计算机视觉，自然语言处理，生物特征识别，搜索引擎，垃圾邮件过滤，推荐系统，广告投放，信用评价，欺诈检测和医疗诊断等应用



### 机器学习分类：

​	可定义为：机器学习是从数据中自动分析获得的模型，并利用模型对未知数据进行预测。可分为：

- 监督学习
- 无监督学习
- 半监督学习
- 强化学习（增强学习）

#### 监督学习：

​	主要特点是要在训练模型时提供给学习系统训练样本以及样本队员的类别标签，因此又称为有导师学习。例：学生从老师那里获取知识，信息，老师提供对错知识、告知最终答案的学习过程。

​	典型的监督学习方法：决策树，支持向量机（SVM），监督式神经网络等分类计算法和线性回归等回归算法。

​	监督学习目标：利用一组带有标签的数据，学习从输入到输出的映射，然后将这种映射关系应用到未知数据上，达到分类（输出时离散的）或回归（输出时连续的）的目的

**监督学习：**

- 目标值：类别——分类问题
- 目标值：连续型数据——回归问题

**示例：**

​	预测明天的气温是多少度？

​	预测明天天气是晴是雨或阴

​	人的年龄预测？

​	人脸识别？



#### 无监督学习

- 无监督学习：主要特征是训练时只提供给学习系统训练样本，而没有样本对应的类别标签信息。例：没有李老师的情况下，学生从书本或网络自学的过程
- 无监督学习中，训练数据包含一组输入向量而没有相应的目标值。这类算法的目标可能是原始数据中相似样本的组合（称作聚类），或者确定数据的分布（称作密度估计），或者把数据从高纬度空间投影到低纬度空间（称作降纬）以便进行可视化。
- 典型的无监督学习方法：聚类学习，自组织神经网络学习。



#### 半监督学习

- 半监督学习方式下，训练数据有部分被识别，部分么有识别，这种模型首先需要学习数据的内在结构，以便合理的组织数据来进行预测。算法上，包括一些对常用监督式学习算法的延伸，这些算法首先试图对未标示数据进行建模，在此基础上再对标识的数据进行预测。
- 例：给学生很多未分类的书本与少量的清单，清单上说明那些书属于同一类别，要求对其他所有书本进行分类



#### 强化学习

- 主要特点是通过试错来发现最优行为策略而不是带有标签的样本学习
- 主要包含四个元素：agent，环境状态，行动，奖励，强化学习的目标就是获得最多的累计奖励
- 例：小孩子走路，下棋（包括下象棋和围棋），机器人，自动驾驶等。





## 监督学习-分类

### 分类学习

**输入**：一组有标签的训练数据（也称观察和评估），标签表明了这些数据（观察）的所属类别。

**输出**：分类模型根据这些训练数据，训练自己的模型参数，学习出一个适合这组数据的分类器，当有新数据（非训练数据）需要进行类别判断，就可以将这组新数据作为输入送给学学习号的分类器进行判断。

**数据集**：

- 训练集：顾名思义就是用来训练模型的已标注数据，用来建立模型，发现规律
- 测试集：也是已标注的数据，通常做法是将标注隐藏，输送给训练好的模型，通过结果与真实标注进行对比，评估模型的学习能力。

**训练集/测试集划分方法**：

​	根据已有标注数据，随机选出一部分数据（70%）作为训练数据，余下的作为测试数据，此外还有交叉验证法等用来评估分类模型



### 分类学习评价标准：

- 精确率：针对预测结果而言，也称查全率，是所有样本中被识别为A类的样本数量与实际属于A类的样本数量的比值。以二分类为例，它表示的是预测为正的样本中有多少是真正的正样本。那么就有两种可能：一种就是把正类预测为正类（TP），另一种就是把负类预测为正类（FP）。精确率P = TP/(TP+FP)【正里面猜正的除猜正的总和】
- 召回率：针对原样本而言，它表示的是样本中正例有多少被预测正确。那也有两种可能：一种是把原来的正类预测成正类（TP），另一种就是把原来正类预测为负类（TN）。召回率P = TP/(TP+TN)【正里面猜正的除正的样本数】



### 分类学习评价标准 例：

假设我们手上有60个正样本，40个负样本，我们要找出所有的正样本。

TP：将正类预测为正类数40，TN：将正类预测为负类数20；FP：将负类预测为正类数10，FN：将负类预测为负类数30.

**准确率**（accuracy）= 预测对的/所有

=(TP+FN)/(TP+FN+FP+TN)=(40+30)/100=70%

**精确率**(precision)：TP/(TP+FP)=40/(40+10)=80%

**召回率**(recall)：TP/(TP+TN)=40/(40+20)=66.7%



### **分类学习应用**：

- 金融：贷款是否批准进行评估
- 医疗诊断：判断一个肿瘤是恶性还是良性
- 欺诈检测：判断一笔银行的交易是都涉嫌欺诈
- 网页分类：判断网页的所属类别，财经或者是娱乐？
- 垃圾邮件分类：判断邮件是否是垃圾邮件



### 分类学习常用算法

- **K近邻分类器（KNN）：**

  ​	通过计算待分类数据点，与已有数据及中的所有数据点的距离。取距离最小的前K个点，根据“少数服从多数”的原则，将这个数据点划分为出现次数最多的那个类别。

- **决策树：**
  - 决策树是一种树形结构的分类器，通过顺序询问分类点的属性决定分类点最终的类别
  - 通常根据特征的信息增益或其他指标，构建一颗决策树。
  - 在分类时，只需要按照决策树中的节点一次进行判断，即可得到样本所属类别
- **朴素贝叶斯：**
  - 朴素贝叶斯分类器是一个以贝叶斯定理为基础的多分类的分类器
  - 对于给出的待分类项，求解在此项出现的条件下各个类别出现的概率，哪个最大，就认为磁带分类项属于哪个类别

$$
P（A|B)=P(B|A)P(A)/P(B)
$$

## 监督学习-回归分析

### 回归：

统计学分析数据的方法，目的在于了解两个或多个变数间是否相关、研究其相关方向与强度，并建立数学模型以便观察特定变数来预测研究者感兴趣的变数

回归分析可以帮助人们了解在自变量变化时因变量的变化量。一般来说，通过回归分析我们可以由给出的自变量估计应变量的条件期望。



### 回归分析应用：

回归方法适合对一些带有时序信息的数据进行预测或者趋势拟合，常用在金融及其他设计时间序列分析的领域：

- 股票趋势预测
- 交通流量预测
- 房价预测



### 回归分析的方法

- 线性回归：是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计方法，其使用形如y=wx+b的线型模拟拟合数据输入和输出之间的映射
  - 实际用途：
    - 利用数据拟合模拟模型进行预测：如果目标是预测或者映射，线性回归可以用来对观测数据集的y和X的值拟合出一个预测的模型。当完成这样一个模型以后，对于一个新增的X值，在没有给定与它相配对的情况下，可以用这个拟合过的模型预测出一个u值
    - 相关性分析去除冗余：给定一个变量y和一些变量X1-Xn，这些变量可能与y相关，线性回归分析可以用来量化y与Xi之间相关性的强度，评估出于y不相关的Xi，并识别出哪些Xi子集包含了关于y的冗余信息。

**房价与房屋尺寸关系的线型拟合**：

**背景**：我们可以根据已知的房屋成交价格和房屋的尺寸进行线性回归，继而可以对已知房屋尺寸，而未知房屋成交价的实例进行成交价格的预测。

**目标**：对房屋成交信息建立回归方程，并依据回归方程对房屋价格进行预测。

- **非线性拟合：多项式回归**
  - 多项式回归是研究因变量与一个或多个自变量间多项式的回归分析方法
  - 如果自变量只有一个时，成为一元多项式回归；如果自变量多个时，成为多元多项式回归；
  - **什么时候用非线性回归：**
    - 在一元回归分析中，如果因变量y与自变量x的关系为非线性的，但是又找不到适当的函数曲线来拟合，则可以通过一元多项式回归
    - 多项式回归的最大优点就是可以通过增加x的高次项对实测点进行逼近，直至满意为止
    - 事实上，多项式回归可以处理相当一类非线性问题，它在回归分析中占有重要的地位，应为任一函数都可以分段用多项式来逼近。