## 结果评估

### 1.模型选择

我们知道机器选择的过程是训练数据进过训练得到一个函数，然后利用函数来预测未知数据。

因此也会出现一些误差：

**泛化误差**：在“未来”样本上的误差

**经验误差**：在训练集上的误差

**例子**：

当我们给机器一些树叶让他学习，第一张给他一颗树他显示是树叶【欠拟合】，给他一片树叶能显示时树叶【合适拟合】，给他一片没有锯齿的树叶显示不是树叶【过拟合】

**对于过拟合和欠拟合我们都有一些方法**：

- AIC准则(Akalikenlnformation Criterion)

$$
AIC = 2k-2ln(L)
$$

- BIC准则(BayesianInformation Criterion)

$$
BIC = kln(n)-2ln(L)
$$

### 2.性能评价指标-分类

**准确率**是指在分类中，分类正确的记录个数占总记录个数的比。

**召回率**也叫查全率，是指在分类中样本的正例有多少被预测正确了。

通常，准确率高时，召回率偏低；召回率高时，准确率偏低。

1.**地震预测**

​	对于地震的预测，我们希望的是召回率非常高，也就是每次地震我们都希望预测出来。这个时候我们可以牺牲准确率。情缘发出1000次警报，把10次都预测对了；也不要100次对了8次。

2.**嫌疑人定罪**

​	基于不错怪一个好人的原则，对于嫌疑人的定罪我们希望是非常准确的。及时有时候我们放过了一些罪犯（召回率低）但是也值得。

| 真实情况 | 预测结果   | 预测结果   |
| -------- | ---------- | ---------- |
| 真实情况 | 正例       | 反例       |
| 正例     | TP(真正例) | FN(假反例) |
| 反例     | FP(假正例) | TN(真反例) |

**准确率**：分类正确的样本个数所占有样本个数的比例
$$
accuracy = \frac{TP+TN}{TP+FN+FP+TN}
$$
**平均准确率**：每个类别下的准确率的算术平均
$$
average\_accuracy = \frac{\frac{TP}{TP+FN}+\frac{TN}{TN+FP}}{2}
$$
**精确率**：分类正确的正样本个数占分类器所有的正样本个数比例
$$
Precision = \frac{TP}{TP+FP}
$$
**召回率**：分类正确的正样本个数占正样本个数的比例
$$
Recall = \frac{TP}{TP+FN}
$$
**F1-Score**:精确率与召回率的调和平均值，它的值更接近与Precision与Recall中较小的值
$$
F1 = \frac{2*precision*recall}{precision+recall}
$$

#### 2.1AUC

ROC:纵轴—真正例率TPR;横轴—假正例率FPR

AUC是ROC曲线下的面积。一般来说，如果ROC是光滑的，那么基本可以判断没有太大的overfitting，这个时候调模型可以只看AUC，面积越大一般认为模型越好。
$$
TPR = \frac{TP}{TP+FP}=\frac{TP}{m_+}\\
FPR = \frac{FP}{FP+TN}=\frac{FP}{m_-}
$$

#### 2.2PR

PR曲线：根据学习器的预测结果按正例可能性大小对样例进行排序，并逐个把样本作为正例进行预测。

- 如果一个学习器对的PR曲线包住了另一个，则可能认为A的性能优于C
- 如果有交叉，综合考虑PR性能，引入平衡点（BEP）,基于BEP比较。

#### 2.3 宏平均&微平均

多分类问题中，若能得到多个混淆矩阵，例如多次训练/测试的结果，多分类的两两混淆矩阵：

**宏（macro-）查准率、查全率、F1**
$$
macro-P=\frac1n\sum_{i=1}^nP_i,\\
macro-R=\frac1n\sum_{i=1}^nR_i,\\
macro-F1 = \frac{2*macro-P*macro-R}{macro-P+macro-R}
$$
**微（micro-）查准率，查全率，F1**
$$
micro-P=\frac{\overline {TP}}{\overline {TP}+\overline {FP}},\\
micro-R=\frac{\overline {TP}}{\overline {TP}+\overline {FN}},\\
micro-F1 = \frac{2*micro-P*micro-R}{micro-P+micro-R}
$$

#### 2.4对数损失

亦被称为逻辑回归损失或交叉熵损失

**二分类问题**：
$$
y\in\{0,1\} 且p = Pr(y=1)则对每个样本的对数损失为\\
Llog(y,p) = -logPr(y|p)=-(ylog(p)+(1-y)log(1-p))
$$
**多分类问题**：

设Y为指示矩阵，即当样本i的分类为k，Yi,k=1设P为估计的概率矩阵，Pi,k=Pr（Ti,k=1）则对每个样本的对数损失为：
$$
Llog(Y_i,P_i)=-logPr(Y_i|P_i)=\sum_{k=1}^Ky_{i,k}logp_{i,k}
$$

#### 2.5 平均绝对误差：

平均绝对误差MAE又被称为I1范数损失
$$
MAE（y,\hat y）= \frac{1}{n_{samples}}\sum_{n=1}^{n_{samples}}|y_i-\hat {y_i}|
$$

#### 2.6平均方差误差：

平均方差误差MSE又称I2范数损失
$$
MAE（y,\hat y）= \frac{1}{n_{samples}}\sum_{n=1}^{n_{samples}}（y_i-\hat {y_i}）^2
$$

#### 2.7均方根差RMSE：

R Squared：是将预测值根只使用均值的情况下相比，看能好多少。
$$
R^2 = 1-\frac{MSE(\hat y ,y)}{Var(y)}
$$

### 3.性能评价指标-聚类

​	**外部指标**对数据集D={X1,X2,...,Xm}，假定通过聚类给出簇划分为C={C1,C2,...,Ck}参考模型给出的簇划分为`C* = {C*1,C*2,...,C*k}`，通过对比C和`C*`来判定聚类结果的好坏

​	**Jaccard系数，FM指数，Rand指数，纯度purity，熵entropy，互信息，Adjusted Rand Index(ARI)，F-measure，Probabilistic Rand Index（PRI）**

​	**内部指标**：对聚类数据结构上的秒数，类内距离小，类间距离大较好。

**DB指数**：衡量同一簇中数据的紧密性，越小越好

**Dunn指数**：衡量同一簇中数据紧密性，越大越好

**Silouette**：衡量同一簇中数据紧密性，越大越好

**Moddurity**：衡量模块性，越大越好