## 回归问题

​	回归分析用于预测输入量变（自变量）和输出变量（因变量）之间的关系，特别是当输入变量的值发生变化时，输出变量值随之发生变化。只管来说回归问题等价于函数拟合，选择一条函数曲线使其很好的拟合已知数据且很好的预测未知数据。

​	回归分析根据**自变量个数**分为【一元回归分析与多元回归分析】，根据**自变量与因变量关系**分为【线性回归分析与非线性回归分析】，根据**因变量个数**分为【简单回归分析与多重回归分析】

### 1.线性回归

​	线性回归算法假设特征和结果满足线性关系系。这就意味着可以将输入项分别乘以一些常量，再将结果加起来的到输出。

**线性回归算法流程**

①选择拟合函数形式

②确定损失函数形式

③训练算法，找到回归系数，如最小二乘，梯度下降等

④使用算法进行数据预测

**线性回归拓展**

​	线性回归拓展算法用简单的基函数替换输入变量x。这样我们就把线性拟合形式拓展到了固定非线性函数的线性组合。

### 2.岭回归

​	岭回归应用结构风险最小化的模型选择策略，在经验风险最小化的基础上加入**正则化因子**。当正则化因子选择为模型参数的**二范数**的时候，整个回归的方法就叫做岭回归。

基本思路：要整个模型在尽可能简单的情况下使得模型的误差最小。

### 3.Lasso回归

​	**Lasso回归**是一种压缩估计。它通过构造一个惩罚函数得到一个较为精炼的模型，使得它压缩一些细数，同时设定一些系数为零。因此保留了子集收缩的优点，是一种产后护理具有**复共线性数据**的**有偏估计**。

​	**Lasso回归**中文翻译为套索，就是拿这个东西吧动物脖子套住，不要他随便乱跑。lasso回归差不多是这个意思，久石让回归系数不要太大，以免造成过度拟合。

**lasso回归可以适应的情况**

​	样本量比较小，但是指标非常多。适用于高位统计，传统的方法无法应对这样的数据，并且Lasso可以进行特征选择。